@article{Simmons1983,
   author={Simmons, Gustavus J.},
   title={The Prisoners' Problem And The Subliminal Channel},
   year=1983,
   pages={1-2}
}
@phdthesis{Hopper2004,
author = {Hopper, Nicholas J.},
advisor = {Blum, Manuel},
title = {Toward a Theory of Steganography},
year = {2004},
isbn = {0496019643},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Informally, steganography refers to the practice of hiding secret messages in communications over a public channel so that an eavesdropper (who listens to all communications) cannot even tell that a secret message is being sent. In contrast to the active literature proposing new concrete steganographic protocols and analysing flaws in existing protocols, there has been very little work on formalizing steganographic notions of security, and none giving complete, rigorous proofs of security in a satisfying model. My thesis initiates the study of steganography from a cryptographic point of view. We give a precise model of a communication channel and a rigorous definition of steganographic security, and prove that relative to a channel oracle, secure steganography exists if and only if one-way functions exist. We give tightly matching upper and lower bounds on the maximum rate of any secure stegosystem. We introduce the concept of steganographic key exchange and public-key steganography, and show that provably secure protocols for these objectives exist under a variety of standard number-theoretic assumptions. We consider several notions of active attacks against steganography, show how to achieve each under standard assumptions, and consider the relationships between these notions. Finally, we extend the concept of steganography as covert communication to include the more general concept of covert computation.},
note = {AAI3143943}
}
@article{Zhang2020,
  author    = {Yizhe Zhang and
               Siqi Sun and
               Michel Galley and
               Yen{-}Chun Chen and
               Chris Brockett and
               Xiang Gao and
               Jianfeng Gao and
               Jingjing Liu and
               Bill Dolan},
  title     = {DialoGPT: Large-Scale Generative Pre-training for Conversational Response
               Generation},
  journal   = {CoRR},
  volume    = {abs/1911.00536},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.00536},
  eprinttype = {arXiv},
  eprint    = {1911.00536},
  timestamp = {Tue, 05 Jan 2021 15:06:52 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-00536.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{OpenAI2019,
abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension , and summarization, are typically approached with supervised learning on task-specific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset-matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
file = {:Users/shanest/Documents/Library/Radford et al/Unknown/Radford et al. - 2019 - Language Models are Unsupervised Multitask Learners.pdf:pdf},
keywords = {model},
title = {{Language Models are Unsupervised Multitask Learners}},
url = {https://openai.com/blog/better-language-models/},
year = {2019}
}
@inproceedings{Meteor2021,
author = {Kaptchuk, Gabriel and Jois, Tushar and Green, Matthew and Rubin, Aviel},
year = {2021},
month = {11},
pages = {1529-1548},
title = {Meteor: Cryptographically Secure Steganography for Realistic Distributions},
doi = {10.1145/3460120.3484550}
}
@misc{MeteorDemo2021,
author = {Kaptchuk, Gabriel and Jois, Tushar and Green, Matthew and Rubin, Aviel},
year = {2021},
month = {08},
day = {24},
howpublished = {\url{https://colab.research.google.com/gist/tusharjois/ec8603b711ff61e09167d8fef37c9b86}},
note = {[Online; accessed 2022-08-24]}
}
@article{PRF1986,
author = {Goldreich, Oded and Goldwasser, Shafi and Micali, Silvio},
title = {How to Construct Random Functions},
year = {1986},
issue_date = {Oct. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {0004-5411},
url = {https://doi.org/10.1145/6490.6503},
doi = {10.1145/6490.6503},
abstract = {A constructive theory of randomness for functions, based on computational complexity, is developed, and a pseudorandom function generator is presented. This generator is a deterministic polynomial-time algorithm that transforms pairs (g, r), where g is any one-way function and r is a random k-bit string, to polynomial-time computable functions undefinedr: {1, … , 2k} → {1, … , 2k}. These undefinedr's cannot be distinguished from random functions by any probabilistic polynomial-time algorithm that asks and receives the value of a function at arguments of its choice. The result has applications in cryptography, random constructions, and complexity theory.},
journal = {J. ACM},
month = {aug},
pages = {792–807},
numpages = {16}
}
@phdthesis{Berndt2017,
author = {Berndt, Sebastian},
advisor = {Liśkiewicz, Maciej},
title = {New Results on Feasibilities And Limitations of Provable Secure Steganography},
year = {2017},
publisher = {Universität zu Lübeck},
address = {Germany}
}