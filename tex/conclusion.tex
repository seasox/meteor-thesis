\chapter{Conclusion}
\label{chap:conclusion}

We have discussed Meteor, an innovative stegosystem that uses generative neural networks to embed a hiddentext into a covert channel.
It achieves that by replacing the randomness used for sampling with an encryption of the hiddentext.

If the encrypted hiddentext is indistinguishable from randomness, this process is secure against chosen hiddentext attackers.
In \autoref{chap:security}, we have seen that this is the case if an attacker is allowed to send up to one query in the SS-CHA game.
Unfortunately, Meteor's security guarantee does not hold for attackers who can send polynomial many queries, because Meteor's output is deterministic.
To fix this, we discussed a modification to Meteor that uses a symmetric encryption scheme (SES) in counter mode to become indeterministic while maintaining indistinguishability from randomness.

We have also modified Meteor for two-way communication for use in the context of instant messaging in \autoref{chap:twowaycommunication}.
To use Meteor in instant messaging, the hiddentext is split into blocks to generate shorter stegotext messages.
While the texts generated by GPT-2 are not very convincing as chat messages, we can easily adapt Meteor to use other GNN models, as long as they satisfy the RRRSS property defined in \autoref{def:rrrss}.
We adapted Meteor to use the DialoGPT model.
The stegotexts generated with the DialoGPT model more closely resemble those found in instant messaging.

We also found that Meteor sometimes generates stegotexts that cannot be decoded correctly in \autoref{chap:reliability}.
These decoding errors happen more frequently the longer the hiddentext is.
This problem occurs due to subword tokenization, a feature of modern GNNs which greatly increases model performance.
We have discussed a modification to the Meteor stegosystem which fixes these decoding errors while -- in the worst case and for some models -- introducing computational decoding overhead exponential in stegotext length.
This modification first tries to detect a decoding error with a checksum of length $\delta$ for message blocks of length $\gamma$ and, in case a decoding error occurs, generates every possible tokenization of a part of the stegotext.
Further research could compare different values for $\gamma$ and $\delta$ to find a good trade-off between stegotext length and computational overhead or develop more efficient techniques to recover from decoding errors.

While the Meteor authors have discussed that the Meteor stegosystem will be adaptable to GPT-3 once it is released, OpenAI, unfortunately, did not yet decide to make their model publicly available and only allows limited access to GPT-3 using a private (and fee-based) online API.
While it would technically still be possible to use this private API with Meteor, its practical use in a stegosystem is limited.
Also, the occurring costs of US\$ 1.12 to US\$ 55.92 per megabyte of hiddentext (US\$ 0.0004 to US\$ 0.02 per 1000 tokens with an average of 3 bits of hiddentext per token) are a problem in practical use \cite{OpenAIPricing2022}.

Fortunately, researchers have built and trained open-source alternatives to GPT-3.
One alternative might be GPT-NeoX, a generative model with 20 billion parameters that can arguably compete with GPT-3 in prediction quality \cite{GPTneo2022}.
Also, GPT-NeoX seems to be compatible with GPT-2, since it uses the same tokenizer and token dictionary.
Further research could incorporate GPT-NeoX as an alternative model for use with the Meteor stegosystem.
First experiments conducted for this thesis have concluded that text generation with large models, i.e., models with parameters an order of magnitude greater than GPT-2's 345 million parameters, requires a considerable amount of computational power which state-of-the-art laptops cannot deliver without hardware acceleration.

Another promising topic for further research could be to adapt the Meteor stegosystem to use public keys instead of symmetric keys and allow steganographic group communication.

The Meteor stegosystem establishes a very promising approach for using generative neural networks in cryptographically secure steganographic systems.
Since it can be expected that computational performance in machine learning will continue to improve in the coming years, steganography on ML models is likely to remain a promising area of research.